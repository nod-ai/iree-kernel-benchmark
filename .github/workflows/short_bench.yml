name: Short Benchmark

on:
  workflow_dispatch:
    inputs:
      selected_backend:
        description: "Which backends to run benchmarks for (wave, iree, torch, hipblaslt, all)"
        required: false
        default: "all"
      selected_kernel:
        description: "Which kernels to run benchmarks for (conv, gemm, attention, all)"
        required: false
        default: "all"
      problems_url:
        description: "URL to problems to benchmark"
        required: true
      tuned_config_url:
        description: "URL to tuning configurations"
        required: false
      metadata:
        description: "Optional: metadata string for tagging the result"
        required: false
      pr_branch:
        description: "Branch name to check out (e.g., feature/opt-pass)"
        required: false
      pr_repository:
        description: "Repository to check out from (e.g., iree-org/wave)"
        required: false
      pr_headsha:
        description: "Head sha of pull request that triggered dispatch"
        required: false

concurrency:
  group: ${{ github.workflow }}-${{ inputs.pr_headsha }}
  cancel-in-progress: true

jobs:
  identifier:
    name: Benchmark Run Identifier
    runs-on: ubuntu-latest
    steps:
      - name: headSha_${{ inputs.pr_headsha || 'undefined' }}
        run: echo run identifier ${{ inputs.pr_headsha || 'undefined' }}

  short_benchmark:
    name: Short Benchmark
    needs: identifier
    runs-on: linux-mi325-1gpu-ossci-nod-ai

    concurrency:
      group: benchmarking
      cancel-in-progress: false

    env:
      WAVE_CACHE_ON: 0

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: "Setup Python"
        uses: actions/setup-python@8d9ed9ac5c53483de85588cdf95a591a75ab9f55
        with:
          python-version: "3.12"

      - name: "Setting up Rust"
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable

      - name: Setup venv
        run: |
          chmod +x ./setup.sh
          ./setup.sh --venv-path bench_venv --wave-repo ${{ inputs.pr_repository }} --wave-branch ${{ inputs.pr_branch }}

      - name: Load Problems from URL
        run: |
          source bench_venv/bin/activate
          curl -o problems.json ${{ inputs.problems_url }}
          python -m json.tool problems.json > /dev/null || { echo "Error: Invalid JSON format"; exit 1; }

      - name: Load Tuning Configuration from URL
        if: ${{ inputs.tuned_config_url }}
        run: |
          source bench_venv/bin/activate
          curl -o tuned_config.json ${{ inputs.tuned_config_url }}
          python -m json.tool tuned_config.json > /dev/null || { echo "Error: Invalid JSON format"; exit 1; }

      - name: Run Benchmarks
        run: |
          source bench_venv/bin/activate
          python3 -m kernel_bench.cli.bench --backend=${{ inputs.selected_backend }} --kernel_type=${{ inputs.selected_kernel }} --load_problems=problems.json --use_tuned=tuned_config.json --machine=mi325x

      - name: Tag result
        if: ${{ inputs.metadata }}
        run: |
          mkdir -p ./results
          cat <<'EOF' > ./results/metadata.txt
          "${{ inputs.metadata }}"

      - name: Upload benchmark results
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1
        with:
          name: benchmark-results
          path: ./results/json/
