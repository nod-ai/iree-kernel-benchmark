name: Short Benchmark

on:
  pull_request:
  workflow_dispatch:
    inputs:
      iterations:
        description: "Number of iterations per benchmark"
        required: false
        default: "3"
      max_kernels:
        description: "Maximum number of kernels to benchmark"
        required: false
        default: "50"
      selected_backend:
        description: "Which backend to run benchmarks for (wave, iree, or all)"
        required: false
        default: "all"
      metadata:
        description: "Optional: metadata string for tagging the result"
        required: false
      pr_branch:
        description: "Branch name to check out (e.g., feature/opt-pass)"
        required: false
      pr_repository:
        description: "Repository to check out from (e.g., iree-org/wave)"
        required: false
      pr_headsha:
        description: "Head sha of pull request that triggered dispatch"
        required: false

concurrency:
  group: ${{ github.workflow }}-${{ inputs.pr_headsha || github.event.number || github.sha }}
  cancel-in-progress: true

jobs:
  identifier:
    name: Benchmark Run Identifier
    runs-on: ubuntu-latest
    steps:
      - name: headSha_${{ inputs.pr_headsha || 'undefined' }}
        run: echo run identifier ${{ inputs.pr_headsha || 'undefined' }}

  short_benchmark:
    name: Short Benchmark
    runs-on: linux-mi325-1gpu-ossci-nod-ai

    concurrency:
      group: benchmarking
      cancel-in-progress: false

    env:
      WAVE_CACHE_ON: 0
      ITERATIONS: ${{ inputs.iterations || '3' }}
      MAX_KERNELS: ${{ inputs.max_kernels || '50' }}
      SELECTED_BACKEND: ${{ inputs.selected_backend || 'all' }}
      WAVE_REPO: ${{ inputs.pr_repository || 'iree-org/wave' }}
      WAVE_BRANCH: ${{ inputs.pr_branch || 'main' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: "Setup Python"
        uses: actions/setup-python@8d9ed9ac5c53483de85588cdf95a591a75ab9f55
        with:
          python-version: "3.12"

      - name: "Setting up Rust"
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable

      - name: Setup venv
        run: |
          python3 -m venv bench_venv
          source bench_venv/bin/activate
          pip install --upgrade pip

          git clone https://github.com/${{ env.WAVE_REPO }}.git
          cd wave
          git checkout ${{ env.WAVE_BRANCH }}
          pip install -r requirements-iree-pinned.txt
          pip install -r pytorch-rocm-requirements.txt
          pip install -r requirements.txt
          pip install -e .

          cd ..
          pip install -r requirements.txt

      # WAVE BACKEND
      - name: Attention - Wave
        if: env.SELECTED_BACKEND == 'wave' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.attentionbench --backend=wave --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      - name: Attention - Wave GQA
        if: env.SELECTED_BACKEND == 'wave' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.attentionbench --backend=wavegqa --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      - name: GEMM - Wave
        if: env.SELECTED_BACKEND == 'wave' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.gemmbench --backend=wave --variants=NT --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      - name: Convolutions - Wave
        if: env.SELECTED_BACKEND == 'wave' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.convbench --backend=wave --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      # IREE BACKEND
      - name: Attention - IREE
        if: env.SELECTED_BACKEND == 'iree' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.attentionbench --backend=iree --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      - name: GEMM - IREE
        if: env.SELECTED_BACKEND == 'iree' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.gemmbench --backend=iree --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      - name: Convolutions - IREE
        if: env.SELECTED_BACKEND == 'iree' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.convbench --backend=iree --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      # TORCH BACKEND
      - name: Attention - Torch
        if: env.SELECTED_BACKEND == 'torch' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.attentionbench --backend=torch --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      - name: GEMM - Torch
        if: env.SELECTED_BACKEND == 'torch' || env.SELECTED_BACKEND == 'all'
        run: |
          source bench_venv/bin/activate
          python -m iree_kernel_benchmark.gemmbench --backend=torch --iterations=$ITERATIONS --max_kernels=$MAX_KERNELS

      # Finish
      - name: Tag result
        if: ${{ inputs.metadata }}
        run: |
          mkdir -p ./results
          cat <<'EOF' > ./results/metadata.txt
          "${{ inputs.metadata }}"

      - name: Upload benchmark results
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1
        with:
          name: benchmark-results
          path: ./results/
